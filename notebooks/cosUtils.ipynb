{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "## Cloud Object Storage Utilities\nThis notebook illustrates several examples of using the python package (ibm_boto3) to manage cloud object storage.\n\nThis notebook is based on the code and utilities from this github repository: https://github.com/biosopher/unofficial-watson-studio-python-utils", 
            "cell_type": "markdown", 
            "metadata": {
                "collapsed": true
            }
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Install required packages\nimport ibm_boto3\nfrom ibm_botocore.client import Config"
        }, 
        {
            "source": "### COS Credentials\nIn the next cell, you need to specify the cloud object storage instance credentials.\nFor details on how to create the credentials for your Cloud Object Storage instance, check the following link:\n\nhttps://github.com/biosopher/unofficial-watson-studio-python-utils/wiki/Save-COS-Credentials-to-cos_credentials.json\n\n**Note** Make sure you use the **{\"HMAC\":true}** parameter when creating the credentials.\n\nThe COS credentials should look as follows:\n\n```{\n  \"apikey\": \"********************\",\n  \"cos_hmac_keys\": {\n    \"access_key_id\": \"*************************\",\n    \"secret_access_key\": \"*************************\"\n  },\n  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n  \"iam_apikey_description\": \"***********************\",\n  \"iam_apikey_name\": \"*****************************\",\n  \"iam_role_crn\": \"***************************\",\n  \"iam_serviceid_crn\": \"****************************\",\n  \"resource_instance_id\": \"********************************\"\n}```\n\nAdditionally, you need to specify the service endpoint for your COS instance. To get that endpoint:\n- Navigate to your COS instance\n- Click on the Endpoint link in the left navigation column\n- Copy the public endpoint corresponding to your  COS location. If your location is us-geo, then select the public endpoint for us-geo.\n\nThe service endpoint would look as follows:\n\n**service_endpoint = 'https://s3-api.us-geo.objectstorage.softlayer.net'**\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cos_credentials = {\n  \"apikey\": \"**************\",\n  \"cos_hmac_keys\": {\n    \"access_key_id\": \"**************\",\n    \"secret_access_key\": \"**************\"\n  },\n  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n  \"iam_apikey_description\": \"**************\",\n  \"iam_apikey_name\": \"**************\",\n  \"iam_role_crn\": \"**************\",\n  \"iam_serviceid_crn\": \"**************\",\n  \"resource_instance_id\": \"**************\"\n}\nservice_endpoint = 'https://s3-api.us-geo.objectstorage.softlayer.net'"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import boto3"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "cos_client = boto3.client('s3', \n                          endpoint_url = service_endpoint, \n                          aws_access_key_id=cos_credentials[\"cos_hmac_keys\"][\"access_key_id\"], \n                          aws_secret_access_key=cos_credentials[\"cos_hmac_keys\"][\"secret_access_key\"])\n\n"
        }, 
        {
            "source": "### COS Utilities\nIn the next cell, we define multiple utilities that are useful when working with Cloud Object Storage.\n\n- **get_all_buckets** returns all the buckets created in your COS instance.\n- **get_objects_in_bucket** returns all the objects in a specific bucket in your COS instance.\n- **create_unique_bucket** creates a new bucket in your COS instance.\n- **upload_file_to_bucket** uploads file from the local notebook environment to a bucket in your COS instance.\n- **download_file_from_bucket** downloads file from the bucket in your COS instance.\n- **download_file_from_url** downloads file from a given url to the local notebook environment.\n- **remove_files_from_dir** removes files from a local directory; mainly used to clean up files when no longer needed.\n\nIf the training data is provided via a URL, then you can use the download_file_from_url and upload_file_to_bucket to get the data to your COS bucket.\n\nIf the training data is provided via a COS bucket, then you can use the download_file_from_bucket and upload_file_to_bucket to get the data to your COS bucket. It may be better to just use the data in the COS bucket specified as opposed to copying to your own COS bucket.\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# load some require python packages\nimport random\nimport string\nimport os\nimport urllib\n\n# Return all buckets in your COS instance\ndef get_all_buckets(cos_client):\n    response = cos_client.list_buckets()\n    allbuckets = []\n    for bucket in response['Buckets']:\n        allbuckets.append(bucket['Name'])\n    return allbuckets\n\n# Return all the objects in a COS bucket\ndef get_objects_in_bucket(cos_client,bucket_name):\n    return cos_client.list_objects(Bucket=bucket_name)\n\n# Create a unique COS bucket\ndef create_unique_bucket(cos_client, bucket_prefix):\n    # Create a random 10 digit string\n    # this random string increases the likelihood of the bucket name to be unique\n    lst = [random.choice(string.ascii_letters + string.digits) for n in range(10)]\n    random_string = \"\".join(lst).lower()\n    bucket = \"%s-%s\" % (bucket_prefix, random_string)\n    \n    #print(\"creating bucket: \", bucket)\n    cos_client.create_bucket(Bucket=bucket)\n    print(\"Bucket %s created\" % bucket)\n\n# Upload objects to COS bucket\ndef upload_file_to_bucket(cos_client,file,bucket):\n    file_name = os.path.basename(file)\n    print(\"Uploading %s to bucket: %s\" % (file_name,bucket))\n    cos_client.upload_file(file, bucket, file_name)\n\n# Download objects from COS bucket\ndef download_file_from_bucket(cos_client, bucket, file_to_download, save_path, is_redownload=False):\n    if not os.path.exists(save_path) or is_redownload:\n        with open(save_path, 'wb') as file:\n            print(\"Downloading %s\" % file_to_download)  # \"\\r\" allows us to overwrite the same line\n            try:\n                cos_client.download_fileobj(bucket, file_to_download, file)\n            except:\n                e = sys.exc_info()[0]\n                print(e.__dict__)\n                if e.response != None:\n                    print(\"Detailed error: \", e.response)\n                print('An error occured downloading %s from %s' % (file_to_download, bucket))\n                os.remove(local_file)\n            finally:\n                file.close()\n\n# Download objects from a URL \ndef download_file_from_url(file_url,save_directory=None):\n    # If save directory provided then don't delete local downloads\n    working_directory = \"temp_cos_files\"\n    if save_directory is not None:\n        working_directory = save_directory\n    os.makedirs(working_directory, exist_ok=True)\n\n    file_name = os.path.basename(file_url)\n    # Delete file if present as perhaps download failed and file corrupted\n    file_path = os.path.join(working_directory, file_name)\n    if os.path.exists(file_path):\n        os.remove(file_path)\n\n    file_path, _ = urllib.request.urlretrieve(file_url, file_path)\n    stat_info = os.stat(file_path)\n    print('Downloaded', file_path, stat_info.st_size, 'bytes.')\n    \n    \n# Remove files from the specified directory in the local environment\ndef remove_files_from_dir(dir):\n    for f in os.listdir(dir):\n        file_path = os.path.join(dir, f)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n"
        }, 
        {
            "source": "### COS Tests\nIn the following cells, we run some tests to make sure we can download and upload files to COS buckets as well as list contents of a bucket and create new buckets.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# List all buckets in your COS instance\nbuckets = get_buckets(cos_client)\nprint(buckets)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Create a new bucket in your COS instance\nbucketName = 'mnist-training-restuls'\ncreate_unique_bucket(cos_client,bucketName)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# List all the objects in the specific bucket\nbucketName = 'mnist-training-data-hxjh7iohms'\nobjects = get_objects_in_bucket(cos_client,bucketName)\ncontents = objects['Contents']\nfor c in contents:\n    print('file: %s ' % c['Key'])\n#print(objects)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Download training data from the following URLs and upload to COS bucket\ndata_links = ['http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n              'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n              'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n              'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz']\n\nbucketName = 'mnist-training-data-hxjh7iohms'\nworking_dir = \"mnist_files\"\nfor file_url in data_links:\n    file_name = os.path.basename(file_url)\n    print(\"file url: %s \" % file_url)\n    print(\"file name: %s \" % file_name)\n    working_dir = \"mnist_files\"\n    download_file_from_url(file_url,working_dir)\n    file_path = os.path.join(working_dir, file_name)\n    upload_file_to_bucket(cos_client,file_path,bucketName)\nremove_files_from_dir(working_dir)    "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Print files in a local dir\nfiles = os.listdir(working_dir)\nprint(files)"
        }, 
        {
            "source": "", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}